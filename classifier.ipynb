{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 22:00:42.395479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 22:00:43.097780: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn import preprocessing\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"retriever/data/train_val_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data['folds'][0]['train'])\n",
    "val_df = pd.DataFrame(data['folds'][0]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.classifier_1 != \"ОТСУТСТВУЕТ\"]\n",
    "val_df = val_df[val_df.classifier_1 != \"ОТСУТСТВУЕТ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train_df['labels'] = le.fit_transform(train_df.classifier_2.values)\n",
    "val_df['labels'] = le.fit_transform(val_df.classifier_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = dict(zip(train_df.classifier_2, train_df.labels))\n",
    "id2label = dict(zip(train_df.labels, train_df.classifier_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34: 'Удаление аккаунта',\n",
       " 14: 'Отклонение/блокировка видео',\n",
       " 15: 'Отключение/подключение монетизации',\n",
       " 6: 'Загрузка видео',\n",
       " 11: 'Навигация',\n",
       " 2: 'Верификация',\n",
       " 23: 'Приложение',\n",
       " 36: 'Управление трансляцией',\n",
       " 20: 'Плеер',\n",
       " 24: 'Продвижение канала',\n",
       " 35: 'Управление плеером',\n",
       " 17: 'Персонализация',\n",
       " 10: 'Монетизация',\n",
       " 28: 'Смена категории/возрастные ограничения',\n",
       " 26: 'Регистрация/Авторизация',\n",
       " 4: 'Встраивание видео',\n",
       " 16: 'Перенос видео с Youtube',\n",
       " 3: 'Воспроизведение видео',\n",
       " 12: 'Нарушение авторских прав',\n",
       " 5: 'Долгая модерация',\n",
       " 33: 'Трансляция',\n",
       " 29: 'Статистика по монетизации',\n",
       " 32: 'Текстовый поиск',\n",
       " 13: 'Недоступность видео',\n",
       " 1: 'Блокировка канала',\n",
       " 8: 'История поиска',\n",
       " 30: 'Студия RUTUBE',\n",
       " 27: 'Система рекомендаций',\n",
       " 25: 'Просмотр трансляции',\n",
       " 7: 'Запрещенный контент',\n",
       " 19: 'Платный контент',\n",
       " 21: 'Подключение/отключение донатов',\n",
       " 0: 'Аналитика',\n",
       " 22: 'Подключение/отключение рекламы',\n",
       " 9: 'Комментарии',\n",
       " 18: 'Персонализация 0',\n",
       " 31: 'ТВ-эфиры',\n",
       " 37: 'Чат/Комментарии'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_classes = train_df['classifier_2'].value_counts().tail(21).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>classifier_1</th>\n",
       "      <th>classifier_2</th>\n",
       "      <th>is_knowledge_base</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>В записи трансляции появятся субтитры?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Привет, а будут ли субтитры в записи трансляции?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Добрый день, появятся ли субтитры в записи тра...</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Будут субтитры на записи трансляции?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Когда добавите субтитры в записи трансляций? Э...</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>А субтитры в записи трансляции будут?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Скажите, планируются ли субтитры для записей т...</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Появятся ли субтитры в записи трансляции?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Есть ли возможность добавить субтитры к записи...</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Субтитры будут в записи трансляций?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Когда можно ожидать субтитры в записи трансляции?</td>\n",
       "      <td>Сейчас такой функции нет, но мы зафиксировали ...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>Доступен ли функционал субтитров трансляции?</td>\n",
       "      <td>Пока такой функции нет, но мы учтем ваше предл...</td>\n",
       "      <td>ПРЕДЛОЖЕНИЯ</td>\n",
       "      <td>Плеер</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "143             В записи трансляции появятся субтитры?   \n",
       "144   Привет, а будут ли субтитры в записи трансляции?   \n",
       "145  Добрый день, появятся ли субтитры в записи тра...   \n",
       "146               Будут субтитры на записи трансляции?   \n",
       "147  Когда добавите субтитры в записи трансляций? Э...   \n",
       "148              А субтитры в записи трансляции будут?   \n",
       "149  Скажите, планируются ли субтитры для записей т...   \n",
       "150          Появятся ли субтитры в записи трансляции?   \n",
       "151  Есть ли возможность добавить субтитры к записи...   \n",
       "152                Субтитры будут в записи трансляций?   \n",
       "153  Когда можно ожидать субтитры в записи трансляции?   \n",
       "854       Доступен ли функционал субтитров трансляции?   \n",
       "\n",
       "                                              response classifier_1  \\\n",
       "143  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "144  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "145  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "146  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "147  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "148  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "149  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "150  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "151  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "152  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "153  Сейчас такой функции нет, но мы зафиксировали ...  ПРЕДЛОЖЕНИЯ   \n",
       "854  Пока такой функции нет, но мы учтем ваше предл...  ПРЕДЛОЖЕНИЯ   \n",
       "\n",
       "    classifier_2 is_knowledge_base  labels  \n",
       "143        Плеер                 0      20  \n",
       "144        Плеер                 0      20  \n",
       "145        Плеер                 0      20  \n",
       "146        Плеер                 0      20  \n",
       "147        Плеер                 0      20  \n",
       "148        Плеер                 0      20  \n",
       "149        Плеер                 0      20  \n",
       "150        Плеер                 0      20  \n",
       "151        Плеер                 0      20  \n",
       "152        Плеер                 0      20  \n",
       "153        Плеер                 0      20  \n",
       "854        Плеер                 0      20  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['classifier_2'] == 'Плеер'][:100-88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in least_classes.items():\n",
    "    samples = train_df[train_df['classifier_2'] == k]\n",
    "    if v == 55:\n",
    "        new = pd.concat([samples, samples])\n",
    "    elif v > 55:\n",
    "        new = pd.concat([samples, samples[:110-len(samples)]])\n",
    "    elif v < 55:\n",
    "        new = pd.concat([samples, samples])\n",
    "        while len(new) < 110:\n",
    "            new = pd.concat([new, samples])\n",
    "        else:\n",
    "            new = pd.concat([new, samples[:110-v]])\n",
    "    train_df = train_df[train_df['classifier_2'] != k]\n",
    "    train_df = pd.concat([train_df, new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier_2\n",
       "Персонализация                            1212\n",
       "Управление трансляцией                     949\n",
       "Загрузка видео                             898\n",
       "Отключение/подключение монетизации         690\n",
       "Регистрация/Авторизация                    561\n",
       "Отклонение/блокировка видео                503\n",
       "Студия RUTUBE                              451\n",
       "Приложение                                 286\n",
       "Верификация                                275\n",
       "Встраивание видео                          226\n",
       "Монетизация                                198\n",
       "Трансляция                                 176\n",
       "Платный контент                            176\n",
       "История поиска                             165\n",
       "Запрещенный контент                        165\n",
       "Воспроизведение видео                      132\n",
       "Просмотр трансляции                        132\n",
       "Персонализация 0                           132\n",
       "Комментарии                                132\n",
       "Подключение/отключение рекламы             132\n",
       "Чат/Комментарии                            132\n",
       "Аналитика                                  132\n",
       "Недоступность видео                        132\n",
       "Текстовый поиск                            132\n",
       "ТВ-эфиры                                   132\n",
       "Блокировка канала                          121\n",
       "Система рекомендаций                       121\n",
       "Смена категории/возрастные ограничения     121\n",
       "Продвижение канала                         121\n",
       "Перенос видео с Youtube                    110\n",
       "Нарушение авторских прав                   110\n",
       "Долгая модерация                           110\n",
       "Управление плеером                         110\n",
       "Плеер                                      110\n",
       "Удаление аккаунта                          110\n",
       "Подключение/отключение донатов             110\n",
       "Статистика по монетизации                  110\n",
       "Навигация                                  110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['classifier_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, split=\"train\")\n",
    "val_ds = Dataset.from_pandas(val_df, split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  train_ds.remove_columns([\"response\", \"classifier_1\", \"classifier_2\", \"is_knowledge_base\", \"__index_level_0__\"])\n",
    "val_ds =  val_ds.remove_columns([\"response\", \"classifier_1\", \"classifier_2\", \"is_knowledge_base\", \"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  train_ds.rename_column(\"question\", \"text\")\n",
    "val_ds =  val_ds.rename_column(\"question\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'ролики из инета защищены авторским правом?', 'labels': 14}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepvk/deberta-v1-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900f0164463b4b0990906ea83272e096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a712b4091b4ebfaf7e68d0e44498a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_ds.map(tokenize, batched=True)\n",
    "tokenized_val = val_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenized_train.shuffle(seed=0)\n",
    "tokenized_val = tokenized_val.shuffle(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")\n",
    "metric1 = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    f1 = metric.compute(predictions=predictions, references=labels,\n",
    "                         average=\"macro\")[\"f1\"]\n",
    "    f1_w = metric.compute(predictions=predictions, references=labels,\n",
    "                         average=\"weighted\")[\"f1\"]\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)[\n",
    "        \"accuracy\"]\n",
    "    \n",
    "    return {\"f1\": f1,\n",
    "            \"f1_weighted\": f1_w,\n",
    "            \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at deepvk/deberta-v1-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"deepvk/deberta-v1-base\", num_labels=len(id2label), label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"classifier_logs\",\n",
    "    learning_rate=2e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,\n",
    "    adam_epsilon=1e-6,\n",
    "    max_grad_norm=1.0,\n",
    "    weight_decay=0.00001,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    warmup_steps=300,\n",
    "    report_to=\"tensorboard\",\n",
    "    seed=42,\n",
    "    use_cpu=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='912' max='912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [912/912 06:28, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.274600</td>\n",
       "      <td>3.829794</td>\n",
       "      <td>0.103209</td>\n",
       "      <td>0.115801</td>\n",
       "      <td>0.148810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.723700</td>\n",
       "      <td>5.186765</td>\n",
       "      <td>0.161074</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>6.215043</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.194149</td>\n",
       "      <td>0.202381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>6.644105</td>\n",
       "      <td>0.176844</td>\n",
       "      <td>0.209823</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>7.377625</td>\n",
       "      <td>0.153418</td>\n",
       "      <td>0.211968</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>7.548243</td>\n",
       "      <td>0.155661</td>\n",
       "      <td>0.210585</td>\n",
       "      <td>0.220238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/alex/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=912, training_loss=0.7069190523685202, metrics={'train_runtime': 393.0604, 'train_samples_per_second': 148.45, 'train_steps_per_second': 2.32, 'total_flos': 3838960122854400.0, 'train_loss': 0.7069190523685202, 'epoch': 6.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b595f8625d396a8e1a27169e1f3cf13ad770e2c72392df9ca9f9b56bdad2d91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
